{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b403340d-09eb-4e6b-b426-99e232db8d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 23:20:04.700319: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-06 23:20:04.704628: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-06 23:20:04.713578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749232204.726302  170782 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749232204.730051  170782 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749232204.741875  170782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749232204.741890  170782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749232204.741891  170782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749232204.741893  170782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-06 23:20:04.745678: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da184e8d-d888-47a9-a0f4-d9dc72d8d2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/garvthakral/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af976a98-8317-40a7-b882-934b458e4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/garvthakral/Downloads/archive (2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fad5994-3647-4093-80d4-ed6220905476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8091 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1749232210.316057  170782 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1749232210.321188  170782 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 32,\n",
    "    image_size = (256,256),\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0febce86-4a77-4cb8-bdd6-ecad902cda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_df = pd.read_csv(\"/home/garvthakral/Downloads/archive (2)/captions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b242cc72-d51d-4aeb-8793-7411898df485",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = []\n",
    "def tokenize_captions(caption):\n",
    "    tokenized_words = word_tokenize(caption)\n",
    "    filtered_tokens = [w for w in tokenized_words if not w.lower() in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a1bdf9-9eac-4261-91b4-5801fdef0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_df[\"tokens\"] = caption_df[\"caption\"].apply(tokenize_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa5be93-5100-48ca-bdd9-9c75f01f4968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "40450    None\n",
       "40451    None\n",
       "40452    None\n",
       "40453    None\n",
       "40454    None\n",
       "Name: tokens, Length: 40455, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = []\n",
    "caption_df[\"tokens\"].apply(lambda x:token_list.append(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4685dfb-4f56-486c-99b4-8bf03390f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_list = []\n",
    "for x in token_list:\n",
    "    for y in x:\n",
    "        joined_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8e7ac1-eba1-486a-89ab-45a5517cadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_frequency = {}\n",
    "for x in joined_list:\n",
    "    if x in token_frequency:\n",
    "        token_frequency[x] += 1\n",
    "    else:\n",
    "        token_frequency[x] = 0\n",
    "        \n",
    "filtered_frequency = {}\n",
    "for x in token_frequency:\n",
    "    if token_frequency[x] > 4:\n",
    "        filtered_frequency[x] = token_frequency[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c83906e-b324-4f61-862f-9f8e1aa2aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "word2Index = {token:idx for token,idx in enumerate(special_tokens)}\n",
    "index2Word = {idx:token for token,idx in word2Index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8837f30a-133e-4a54-960f-45627c244595",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']  \n",
    "vocabulary += list(filtered_frequency.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f04f29c1-4978-4c63-9ffd-6c477ed7b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f74adc59-aba7-4c0c-8c80-fc6581a31a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_to_index(caption):\n",
    "    caption_list = [word2idx['<SOS>']]  \n",
    "    for x in caption:\n",
    "        if x in word2idx:\n",
    "            caption_list.append(word2idx[x])\n",
    "        else:\n",
    "            caption_list.append(word2idx['<UNK>'])  \n",
    "    caption_list.append(word2idx['<EOS>'])  \n",
    "    return caption_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53ab3a12-9202-4182-8cc9-2eedc3bca572",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_df[\"tokens_ind\"] = caption_df[\"tokens\"].apply(caption_to_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
